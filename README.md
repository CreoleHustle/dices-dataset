This repository contains two datasets with multi-turn adversarial conversations generated by human agents interacting with a dialog model. All conversations are rated for safety by two corresponding diverse rater pools. Details for all safety ratings can be found in the corresponding README.md files.

Dataset 1: `990/diverse_safety_adversarial_dialog_990.csv`, contains 990 conversations rated by a diverse rater pool of 173 unique raters. Each conversation is rated with three safety top-level categories and one overall conversation comprehension question. Raters were recruited so that the number of raters for each conversation was balanced by gender (Man, Woman) and locale (US, India). Each rater rated only a sample of the conversation. Each conversation has 20 unique ratings. Total number of rows in this dataset is 72104.

Dataset 2: `350/diverse_safety_adversarial_dialog_350.csv`, contains 350 conversations rated by a diverse rater pool of 123 unique raters. Each conversation is rated with five safety top-level categories and one overall comprehension question of the conversation. Raters were recruited were balanced by gender (man or woman), race/ethnicity (White, Black, Latine, Asian, Multiracial) and each rater rated all items.  Each rater rated all conversations. Each conversation has 104 unique ratings. Total number of rows in this dataset is 43050.

Each directory contains the dataset csv file and a README.md file describing the schema for the corresponding dataset.
